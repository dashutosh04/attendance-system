<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>AI-Based Voice Attendance System</title>
    <style>
        body {
            font-family: Arial, Helvetica, sans-serif;
            margin: 40px;
            line-height: 1.6;
            background-color: #ffffff;
            color: #222;
        }
        h1, h2, h3 {
            color: #0a3d62;
        }
        code {
            background-color: #f4f4f4;
            padding: 3px 6px;
            border-radius: 4px;
            font-size: 0.95em;
        }
        pre {
            background-color: #f4f4f4;
            padding: 12px;
            overflow-x: auto;
            border-radius: 6px;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }
        table, th, td {
            border: 1px solid #ccc;
        }
        th, td {
            padding: 10px;
            text-align: left;
        }
        th {
            background-color: #eaf2f8;
        }
        .section {
            margin-bottom: 40px;
        }
        .highlight {
            background: #e8f6f3;
            padding: 10px;
            border-left: 5px solid #1abc9c;
        }
    </style>
</head>

<body>

<h1>AI-Based Voice Attendance System</h1>
<p><strong>Type:</strong> Minor Project</p>
<p><strong>Domain:</strong> Artificial Intelligence, Speech Processing, Biometrics</p>

<div class="section">
<h2>1. Introduction</h2>
<p>
Traditional attendance systems are time-consuming, error-prone, and vulnerable to proxy attendance.
This project proposes an <strong>AI-based automated attendance system</strong> that uses
<strong>speech intent detection</strong> and <strong>speaker recognition</strong> to mark attendance.
</p>
<p>
The system announces roll numbers, listens for student responses, verifies identity using voice biometrics,
and records attendance automatically with manual override support.
</p>
</div>

<div class="section">
<h2>2. Objectives</h2>
<ul>
    <li>Automate attendance marking using voice</li>
    <li>Prevent proxy attendance using speaker recognition</li>
    <li>Provide fallback manual control for instructors</li>
    <li>Maintain explainable confidence scores</li>
    <li>Generate date-wise attendance records</li>
</ul>
</div>

<div class="section">
<h2>3. System Architecture</h2>
<p>The system is modular and consists of the following components:</p>

<table>
<tr><th>Module</th><th>Description</th></tr>
<tr><td>GUI</td><td>User interface for enrollment, attendance, and monitoring</td></tr>
<tr><td>Audio Module</td><td>Handles microphone input and beep signals</td></tr>
<tr><td>TTS Module</td><td>Announces roll numbers and system responses</td></tr>
<tr><td>Speaker Recognition</td><td>Verifies speaker identity using AI</td></tr>
<tr><td>Speech Recognition</td><td>Detects spoken words like "present"</td></tr>
<tr><td>Logging System</td><td>Tracks system events for transparency</td></tr>
</table>
</div>

<div class="section">
<h2>4. Technologies Used</h2>

<table>
<tr><th>Technology</th><th>Purpose</th></tr>
<tr><td>Python</td><td>Main programming language</td></tr>
<tr><td>SpeechBrain</td><td>Speaker recognition (ECAPA-TDNN)</td></tr>
<tr><td>SpeechRecognition</td><td>Speech-to-text (intent detection)</td></tr>
<tr><td>pyttsx3</td><td>Offline text-to-speech</td></tr>
<tr><td>sounddevice</td><td>Microphone audio capture</td></tr>
<tr><td>CustomTkinter</td><td>Modern GUI</td></tr>
<tr><td>Pandas</td><td>CSV generation</td></tr>
</table>
</div>

<div class="section">
<h2>5. Speaker Recognition Model</h2>
<p>
The system uses a <strong>pretrained ECAPA-TDNN model</strong> from SpeechBrain.
This model converts voice audio into fixed-length numerical vectors called <em>speaker embeddings</em>.
</p>

<div class="highlight">
<strong>Model Name:</strong> ECAPA-TDNN (trained on VoxCeleb dataset)<br>
<strong>Purpose:</strong> Identify who is speaking, not what is spoken
</div>

<p>
Speaker identity is verified by computing <strong>cosine similarity</strong> between live and enrolled embeddings.
</p>
</div>

<div class="section">
<h2>6. Speech Recognition (Intent Detection)</h2>
<p>
Speech-to-text is used only to detect <strong>intent</strong>, not identity.
Accepted intent words include:
</p>

<pre>
present
yes
yes sir
here
</pre>

<p>
This separation improves robustness and avoids over-dependence on speech recognition accuracy.
</p>
</div>

<div class="section">
<h2>7. Enrollment Process</h2>
<ol>
    <li>Student provides roll number</li>
    <li>Multiple voice samples are recorded</li>
    <li>Each sample is converted to an embedding</li>
    <li>An adaptive threshold is calculated</li>
    <li>Data is stored securely</li>
</ol>

<p>
Adaptive thresholds reduce false rejections by accounting for voice variation.
</p>
</div>

<div class="section">
<h2>8. Attendance Workflow</h2>
<ol>
    <li>System announces roll number</li>
    <li>Beep sound indicates recording</li>
    <li>Speech intent is detected</li>
    <li>Speaker identity is verified (optional)</li>
    <li>Attendance is marked</li>
</ol>

<p>
If automatic verification fails, the system requests <strong>manual instructor intervention</strong>.
</p>
</div>

<div class="section">
<h2>9. GUI Features</h2>
<ul>
    <li>Enroll / Train students</li>
    <li>Start attendance session</li>
    <li>Enable / disable voice similarity check</li>
    <li>Manual present / absent buttons</li>
    <li>Confidence graph popup</li>
</ul>
</div>

<div class="section">
<h2>10. Confidence Score</h2>
<p>
Confidence is a normalized value derived from speaker similarity.
It reflects system certainty but is not a probability.
</p>

<div class="highlight">
Confidence helps explain decisions rather than replace human judgment.
</div>
</div>

<div class="section">
<h2>11. Logging System</h2>
<p>
All events are logged using a structured format:
</p>

<pre>
[timestamp] | [action] | [status] | message
</pre>

<p>
This ensures transparency, debugging capability, and explainability.
</p>
</div>

<div class="section">
<h2>12. Output Files</h2>
<ul>
    <li><code>attendance_YYYY-MM-DD.csv</code> — date-wise attendance</li>
    <li><code>attendance.log</code> — system activity log</li>
</ul>
</div>

<div class="section">
<h2>13. Limitations</h2>
<ul>
    <li>Performance depends on microphone quality</li>
    <li>High background noise may affect accuracy</li>
    <li>Internet required for online speech recognition</li>
</ul>
</div>

<div class="section">
<h2>14. Future Enhancements</h2>
<ul>
    <li>Offline speech recognition (Vosk)</li>
    <li>Face recognition integration</li>
    <li>Adaptive confidence learning</li>
    <li>Analytics dashboard</li>
    <li>Web-based deployment</li>
</ul>
</div>

<div class="section">
<h2>15. Conclusion</h2>
<p>
This project demonstrates a practical and reliable AI-based attendance system
that combines biometric verification, speech processing, and user-centric design.
The modular architecture allows future expansion while maintaining explainability
and instructor control.
</p>
</div>

</body>
</html>
